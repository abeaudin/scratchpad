input {
  file {
    path           => "/usr/share/logstash/traindata.xml"   # one XML record per line
    start_position => "beginning"
    sincedb_path   => "/dev/null"
    codec          => plain { charset => "UTF-8" }
  }
}

filter {

# Parse the XML, keep the full DOM under the 'xml' field
  xml {
    source      => "message"
    target      => "xml"       
    store_xml   => true
    force_array => false
  }

# Flatten the nested hash so every attribute/element becomes
# a top-level field (recursive, handles arrays-of-hashes too)
  ruby {
    code => '
      def flatten(prefix, value, out)
        case value
        when Hash
          value.each { |k, v| flatten([prefix, k].compact.join("_"), v, out) }
        when Array
          if value.size == 1 && value.first.is_a?(Hash)
            flatten(prefix, value.first, out)
          else
            out[prefix] = value
          end
        else
          out[prefix] = value
        end
      end

      tree = event.get("xml")
      if tree
        flat = {}
        flatten(nil, tree, flat)
        flat.each { |k, v| event.set(k, v) }
        event.remove("xml")      # drop the nested copy to save space
      end
    '
  }

# convert SOURCE_CREATE_TMS=30-APR-25 into @timestamp
  if [Supply_SOURCE_CREATE_TMS] {
    date {
      match        => ["Supply_SOURCE_CREATE_TMS", "dd-MMM-yy"]
      locale       => "en"
      timezone     => "UTC"
      target       => "@timestamp"
      remove_field => ["Supply_SOURCE_CREATE_TMS"]
    }
  }

# Optional type conversions; add any you need
  mutate {
    convert => {
      "Supply_SUPPLY_ID"        => "integer"
      "Supply_ORIGIN_SUPPLY_ID" => "integer"
    }
  }

  mutate { remove_field => ["message"] } 
}

output {
  stdout { codec => rubydebug }

elasticsearch {
    hosts  => ["https://hostname-here:443"]
    password => "password"
    user => "elastic"
    index  => "trainsupply-%{+YYYY.MM.dd}"
  }
}

